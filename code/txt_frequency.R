#!/usr/bin/env Rscript

# Source the plotting script
source("code/plotting.R")

# Main function
analyze_frequency <- function(date_hour) {
  
  # Read data words
  file_name <- paste0("datos/outputData/words_", date_hour, ".txt")
  
  # Load the table generated by the second script
  data_words <- read.table(file_name, sep = "\t", header = TRUE)
  
  # Count term frequency in each book
  docs_words <- data_words %>% 
    count(document, word, sort = TRUE)
  
  # Count number of terms in each book
  total_words <- docs_words %>% 
    group_by(document) %>% 
    summarize(total = sum(n))
  
  # Join both
  docs_words <- left_join(docs_words, total_words, by = "document")
  
  # Plot term frequency distribution
  term_frequency_plot <- plot_term_frequency(docs_words, title="Distribución de Frecuencia de Términos", xlab="Frecuencia de Términos", ylab="Conteo")
  save_plot_to_pdf(term_frequency_plot, paste0("term_frequency_", date_hour, ".pdf"))
  
  # Apply Zipf's Law and plot
  zipfs_law_plot <- plot_zipfs_law(docs_words, title="Ley de Zipf", xlab="Rango", ylab="Frecuencia de Término")
  save_plot_to_pdf(zipfs_law_plot, paste0("zipfs_law_", date_hour, ".pdf"))
  
  # Calculate TF-IDF and plot
  docs_words <- docs_words %>%
    bind_tf_idf(word, document, n)
  tf_idf_plot <- plot_tf_idf(docs_words, title="Top 10 Palabras por TF-IDF", xlab=NULL, ylab="tf-idf")
  save_plot_to_pdf(tf_idf_plot, paste0("tf_idf_", date_hour, ".pdf"))
}

# # Read data words
# file_name <- paste0("datos/outputData/words_", date_hour, ".txt")

# # Load the table generated by the second script
# #data_words <- read.table("datos/outputData/words_01-07-2024_18:18.txt", sep = "\t", header = TRUE)
# data_table <- read.table(file_name, sep = "\t", header = FALSE, col.names = c("document", "date"))

# # count term frequency in each book
# docs_words = data_words %>% 
#   count(document, word, sort = TRUE)

# # count number of terms in each book
# total_words = docs_words %>% 
#   group_by(document) %>% 
#   summarize(total = sum(n))
# #join both
# docs_words = left_join(docs_words, total_words)

# ggplot(data = docs_words, aes(n/total, fill = document)) +
#   geom_histogram(show.legend = FALSE) +
#   #xlim(NA, 0.0009) +
#   facet_wrap(~document, ncol = 3, scales = "free_y")

# #  Ley de Zipf.s
# freq_by_rank <- docs_words %>% 
#   group_by(document) %>% 
#   mutate(rank = row_number(),
#          'term frequency' = n/total)

# freq_by_rank %>% 
#   ggplot(aes(rank, `term frequency`, color = document)) + 
#   geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
#   scale_x_log10() +
#   scale_y_log10()

# # métrica TF-IDF

# docs_words <- docs_words %>%
#   bind_tf_idf(word, document, n)

# docs_words %>%
#   select(-total) %>%
#   arrange(desc(tf_idf))

# docs_words %>%
#   arrange(desc(tf_idf)) %>%
#   mutate(word = factor(word, levels = rev(unique(word)))) %>% 
#   group_by(document) %>% 
#   top_n(10) %>% 
#   ungroup() %>%
#   ggplot(aes(word, tf_idf, fill = document)) +
#   geom_col(show.legend = FALSE) +
#   labs(x = NULL, y = "tf-idf") +
#   facet_wrap(~document, ncol = 2, scales = "free") +
#   coord_flip()

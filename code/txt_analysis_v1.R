#!/usr/bin/env Rscript

main_process_texts <- function(directory, language, ngram_number, date_hour) {

# Function to remove accent marks from a text
remove_accents <- function(texto) {
  iconv(texto, to = "ASCII//TRANSLIT")
}

file_name <- paste0("data_table_", date_hour, ".txt")

# Load the table generated by the second script
data_table <- read.table(file_name, sep = "\t", header = FALSE, col.names = c("space", "date"))


# Format the dates in the 'date' column from "dd/mm/yyyy" to "dd-mm-yyyy"
data_table$date <- gsub("/", "-", data_table$date)

# Basename
data_table$space <- basename(data_table$space)
data_table$origin_space <- data_table$space

# Removed tag
data_table$space <- gsub("\\.[^.]+$", "", data_table$space)

# IF is numeric, is numeric, else is character, is character add conditional!
# infoText <- if (is.numeric(data_table$date[1])) {
#   tibble(
#     date = numeric(),
#     space = character(),
#     paragraph = numeric(),
#     text = character()
#   )
# } else {
#   tibble(
#     date = character(),
#     space = character(),
#     paragraph = numeric(),
#     text = character()
#   )
# }
infoText <- if (is.numeric(data_table$date[1])) {
  tibble(
    date = numeric(),
    space = character(),
    paragraph = numeric(),
    total_words = numeric(),
    text = character()
  )
} else {
  tibble(
    date = character(),
    space = character(),
    paragraph = numeric(),
    total_words = numeric(),
    text = character()
  )
}

# Read the files and create the initial tibble
# for (i in seq_along(data_table$origin_space)) {
#   speech <- readLines(file.path(directory, data_table$origin_space[i]))
#   temporal <- tibble(date = data_table$date[i],
#                      space = data_table$space[i],
#                      paragraph = seq_along(speech),
#                      text = speech)
#   infoText <- bind_rows(infoText, temporal)
# }

for (i in seq_along(data_table$origin_space)) {
  speech <- readLines(file.path(directory, data_table$origin_space[i]))
  
  # Count the words in each paragraph
  word_counts <- sapply(strsplit(speech, "\\s+"), length)
  
  # Calculate the total words in the document
  total_words <- sum(word_counts, na.rm = TRUE)
  
  temporal <- tibble(date = data_table$date[i],
                     space = data_table$space[i],
                     paragraph = seq_along(speech),
                     total_words = total_words,
                     text = speech)
  
  infoText <- bind_rows(infoText, temporal)
}

infoText <- infoText %>%
  mutate(space = factor(space, levels = unique(space)),
         date = factor(date))

# Read stop words according to the specified language
if (tolower(language) == "sp") {
  empty <- read_tsv("datos/vacias.txt", col_names = "word")
} else if (tolower(language) == "en") {
  empty <- stop_words %>% select(word)
} else {
  stop("Invalid language argument. Use 'SP' or 'EN'.")
}

# Function to generate tokens and filter ngrams
generate_ngrams <- function(infoText, n) {
  tokens <- infoText %>%
    unnest_tokens(word, text, token = "ngrams", n = n) %>%
    separate(word, into = paste0("word", 1:n), sep = " ") %>%
    filter(across(starts_with("word"), ~ !grepl("\\d+", .) & !(. %in% empty$word))) %>%
    unite(word, starts_with("word"), sep = " ")
  
  return(tokens)
}

# Generate the ngrams and filter
if (ngram_number == "4") {
  infoText_token <- generate_ngrams(infoText, 4)
} else if (ngram_number == "3") {
  infoText_token <- generate_ngrams(infoText, 3)
} else if (ngram_number == "2") {
  infoText_token <- generate_ngrams(infoText, 2)
} else if (ngram_number == "1" || ngram_number == "") {
  infoText_token <- infoText %>%
    unnest_tokens(word, text) %>%
    filter(!grepl("\\d+", word) & !word %in% empty$word)
} else {
  stop("Invalid ngram value. Use 1, 2, or 3.")
}

# Save the result to a file
output_dir <- "datos/outputData"
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

textWord <- file.path("datos/outputData/", paste0("words_", date_hour, ".txt"))
write.table(infoText_token, file = textWord, row.names = FALSE, col.names = TRUE, sep = "\t", quote = FALSE)

}
